{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "src= \"/home/pallavi/Audio_Speech/Actor_24\"\n",
    "\n",
    "for file in os.listdir(src):\n",
    "    name = file[:file.rfind(\".\")]\n",
    "    #ffmpeg -y -i $filename -map_metadata -1 -codec copy $newfilename\n",
    "    subprocess.call([\"ffmpeg\",\"-y\",\"-i\",src+\"/\"+name+\".wav\",\"-map_metadata\",\"-1\",\"-codec\",\"copy\",src+\"/\"+name+\".wav\"])\n",
    "    #subprocess.call([\"fmpeg\", \"-i\", sourcedir+\"/\"+name+\".avi\", sourcedir+\"/\"+name+\".webm\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "rate, data = scipy.io.wavfile.read(\"/home/pallavi/Audio_Speech/All/03-01-08-01-02-02-01.wav\")\n",
    "print (rate)\n",
    "print(len(data))\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "print(data.shape[0])\n",
    "plt.plot(data[:114688])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "filename=\"03-01-05-01-01-01-24.wav\"\n",
    "rate, data = scipy.io.wavfile.read(\"/home/pallavi/Audio_Speech/Actor_24/\"+filename)\n",
    "emo=filename[7]\n",
    "print(emo)\n",
    "plt.plot(data[:114688])\n",
    "data=data/ (2.**15)\n",
    "plt.plot(data[:114688])\n",
    "print (rate)\n",
    "print(len(data))\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "data=data.tolist()\n",
    "print(data[10])\n",
    "#print(data)\n",
    "a=array(data)\n",
    "print(a.dtype)\n",
    "print(a.shape)\n",
    "plt.plot(data[:114688])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=data[:]\n",
    "timeArray = np.arange(0, 114688, 1)\n",
    "timeArray = timeArray / rate\n",
    "print(timeArray.shape)\n",
    "print(d.shape)\n",
    "timeArray = timeArray * 1000  #scale to milliseconds\n",
    "plt.plot(timeArray, d, color='k')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "\n",
    "import os\n",
    "path=\"/home/pallavi/Audio_Speech/All\"\n",
    "n=114688\n",
    "arr = np.empty(shape=(0,n))\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "    rate, data = scipy.io.wavfile.read(\"/home/pallavi/Audio_Speech/All/\"+filename)\n",
    "    if data.shape[0]==n:\n",
    "        arr=np.append(arr,[data],axis=0)\n",
    "    else:\n",
    "        print(filename)\n",
    "print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "\n",
    "import os\n",
    "path=\"/home/pallavi/Audio_Speech/All2\"\n",
    "n=114688\n",
    "a = np.empty(shape=(0,n))\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "    rate, data = scipy.io.wavfile.read(\"/home/pallavi/Audio_Speech/All2/\"+filename)\n",
    "    if data.shape[0]==n:\n",
    "        a=np.append(a,[data],axis=0)\n",
    "    else:\n",
    "        print(filename)\n",
    "print(len(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all files to derive data and save into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "\n",
    "import os\n",
    "path=\"/home/pallavi/Audio_Speech/Allfiles\"\n",
    "n=114688\n",
    "m=1435\n",
    "#arr = np.empty(shape=(0,n-40000))\n",
    "emotion = np.empty([0, 1], dtype=int)\n",
    "e=[]\n",
    "arr=[]\n",
    "for filename in os.listdir(path):\n",
    "    emo=int(filename[7])\n",
    "    rate, data = scipy.io.wavfile.read(\"/home/pallavi/Audio_Speech/Allfiles/\"+filename)\n",
    "    #print(data.shape)\n",
    "    if data.shape[0]==n:\n",
    "        e.append(emo)\n",
    "        data = data[35763:]\n",
    "        data=data.tolist()\n",
    "        arr.append(data)\n",
    "        #emotion=np.append(emotion,emo,axis=0)\n",
    "        #arr=np.append(arr,[data],axis=0)\n",
    "    else:\n",
    "        print(filename)\n",
    "print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print((arr.shape))\n",
    "train = arr[:1300]\n",
    "test = arr[1300:]\n",
    "print(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "i=0\n",
    "for l in arr:\n",
    "    l.append(e[i])\n",
    "    i=i+1\n",
    "    final.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('speech.csv','w') as myfile:\n",
    "    wr = csv.writer(myfile,quoting=csv.QUOTE_NONE)\n",
    "    for f in final:\n",
    "        wr.writerow(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('speech.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import speechpy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_folder = \"home/\"\n",
    "\n",
    "class_labels = [\"Neutral\", \"Angry\", \"Happy\", \"Sad\"]\n",
    "\n",
    "mslen = 100000  # Empirically calculated for the given dataset\n",
    "\n",
    "\n",
    "def read_wav(filename):\n",
    "    \"\"\"\n",
    "    Read the wav file and return corresponding data\n",
    "    :param filename: name of the file\n",
    "    :return: return tuple containing sampling frequency and signal\n",
    "    \"\"\"\n",
    "    return wav.read(filename)\n",
    "\n",
    "\n",
    "def get_data(flatten=True, mfcc_len=39):\n",
    "    \"\"\"\n",
    "    Read the files get the data perform the test-train split and return them to the caller\n",
    "    :param mfcc_len: Number of mfcc features to take for each frame\n",
    "    :param flatten: Boolean specifying whether to flatten the data or not\n",
    "    :return: 4 arrays, x_train x_test y_train y_test\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_fs = 0\n",
    "    min_sample = int('9' * 10)\n",
    "    s = 0\n",
    "    cnt = 0\n",
    "    cur_dir = os.getcwd()\n",
    "    os.chdir('..')\n",
    "    os.chdir(dataset_folder)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        print \"started reading folder\", directory\n",
    "        os.chdir(directory)\n",
    "        for filename in os.listdir('.'):\n",
    "            fs, signal = read_wav(filename)\n",
    "            max_fs = max(max_fs, fs)\n",
    "            s_len = len(signal)\n",
    "            # pad the signals to have same size if lesser than required\n",
    "            # else slice them\n",
    "            if s_len < mslen:\n",
    "                pad_len = mslen - s_len\n",
    "                pad_rem = pad_len % 2\n",
    "                pad_len /= 2\n",
    "                signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "            else:\n",
    "                pad_len = s_len - mslen\n",
    "                pad_rem = pad_len % 2\n",
    "                pad_len /= 2\n",
    "                signal = signal[pad_len:pad_len + mslen]\n",
    "            min_sample = min(len(signal), min_sample)\n",
    "            mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=mfcc_len)\n",
    "\n",
    "            if flatten:\n",
    "                # Flatten the data\n",
    "                mfcc = mfcc.flatten()\n",
    "            data.append(mfcc)\n",
    "            labels.append(i)\n",
    "            cnt += 1\n",
    "        print \"ended reading folder\", directory\n",
    "        os.chdir('..')\n",
    "    os.chdir(cur_dir)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435\n",
      "int32\n",
      "(1435, 60000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "from numpy import array\n",
    "import os\n",
    "\n",
    "path=\"C:/Users/Apurv/Allfiles/\"\n",
    "n=114688\n",
    "m=1435\n",
    "#arr = np.empty(shape=(0,n-40000))\n",
    "#emotion = np.empty([0, 1], dtype=int)\n",
    "e=[]\n",
    "arr=[]\n",
    "app=np.zeros([60000, 1435])\n",
    "i=0\n",
    "for filename in os.listdir(path):\n",
    "    emo=int(filename[7])\n",
    "    rate, data = scipy.io.wavfile.read(\"C:/Users/Apurv/Allfiles/\"+filename)\n",
    "    if data.shape[0]==n:\n",
    "        e.append(emo)\n",
    "        data = data[54688:]\n",
    "        for j in range(0,60000):\n",
    "            app[j][i]=data[j]\n",
    "        data=data.tolist()\n",
    "        arr.append(data)\n",
    "        #emotion=np.append(emotion,emo,axis=0)\n",
    "        #arr=np.append(arr,[data],axis=0)\n",
    "    else:\n",
    "        print(filename)\n",
    "    i=i+1\n",
    "    \n",
    "print(len(arr))\n",
    "a=array(arr)\n",
    "print(a.dtype)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454.0\n",
      "float64\n",
      "(60000, 1435)\n"
     ]
    }
   ],
   "source": [
    "print(app[6000][105])\n",
    "print(app.dtype)\n",
    "print(app.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1435, 60000)\n",
      "(1435,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "capp=app\n",
    "capp=np.transpose(capp)\n",
    "print(capp.shape)\n",
    "e=array(e)\n",
    "print(e.shape)\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from keras.utils import to_categorical\n",
    "labels = []\n",
    "for i in range(0,1435):\n",
    "    lab=to_categorical(e[i], 9)\n",
    "    lab=lab[1:]\n",
    "    labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1435, 75, 800)\n",
      "float64\n",
      "float64\n",
      "(1435, 8)\n"
     ]
    }
   ],
   "source": [
    "capp = capp.reshape(1435, 75, 800)\n",
    "print(capp.shape)\n",
    "print(capp.dtype)\n",
    "print(capp[90][0][58].dtype)\n",
    "labels=array(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1435, 75, 800)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(capp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1435/1435 [==============================] - 10s 7ms/step - loss: 2.0727 - acc: 0.1436\n",
      "Epoch 2/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 2.0511 - acc: 0.1951\n",
      "Epoch 3/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 2.0223 - acc: 0.2111\n",
      "Epoch 4/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.9712 - acc: 0.2411\n",
      "Epoch 5/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.9151 - acc: 0.2509\n",
      "Epoch 6/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.8811 - acc: 0.2620\n",
      "Epoch 7/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.8568 - acc: 0.2655\n",
      "Epoch 8/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.8309 - acc: 0.2683\n",
      "Epoch 9/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.8188 - acc: 0.2753\n",
      "Epoch 10/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7943 - acc: 0.2857\n",
      "Epoch 11/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.7819 - acc: 0.2955\n",
      "Epoch 12/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7635 - acc: 0.3052\n",
      "Epoch 13/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7485 - acc: 0.3268\n",
      "Epoch 14/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7457 - acc: 0.3233\n",
      "Epoch 15/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7400 - acc: 0.3345\n",
      "Epoch 16/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7136 - acc: 0.3422\n",
      "Epoch 17/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7062 - acc: 0.3540\n",
      "Epoch 18/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.7036 - acc: 0.3617\n",
      "Epoch 19/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6927 - acc: 0.3638\n",
      "Epoch 20/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6849 - acc: 0.3491\n",
      "Epoch 21/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6932 - acc: 0.3456\n",
      "Epoch 22/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6749 - acc: 0.3519\n",
      "Epoch 23/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6863 - acc: 0.3436\n",
      "Epoch 24/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.6519 - acc: 0.3666\n",
      "Epoch 25/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.6350 - acc: 0.3784\n",
      "Epoch 26/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.6204 - acc: 0.3721\n",
      "Epoch 27/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.6307 - acc: 0.3812\n",
      "Epoch 28/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.6186 - acc: 0.3777\n",
      "Epoch 29/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.6069 - acc: 0.3902\n",
      "Epoch 30/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5822 - acc: 0.3882\n",
      "Epoch 31/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5668 - acc: 0.4007\n",
      "Epoch 32/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5704 - acc: 0.3840\n",
      "Epoch 33/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.5629 - acc: 0.3923\n",
      "Epoch 34/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.5468 - acc: 0.4098\n",
      "Epoch 35/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5190 - acc: 0.4188\n",
      "Epoch 36/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5179 - acc: 0.4202\n",
      "Epoch 37/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5269 - acc: 0.4300\n",
      "Epoch 38/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5288 - acc: 0.4098\n",
      "Epoch 39/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.5308 - acc: 0.4105\n",
      "Epoch 40/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.5204 - acc: 0.4230\n",
      "Epoch 41/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4824 - acc: 0.4362\n",
      "Epoch 42/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.5013 - acc: 0.4279\n",
      "Epoch 43/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.4814 - acc: 0.4453\n",
      "Epoch 44/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4695 - acc: 0.4411\n",
      "Epoch 45/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4545 - acc: 0.4411\n",
      "Epoch 46/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4457 - acc: 0.4578\n",
      "Epoch 47/60\n",
      "1435/1435 [==============================] - 6s 5ms/step - loss: 1.4389 - acc: 0.4592\n",
      "Epoch 48/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.4332 - acc: 0.4641\n",
      "Epoch 49/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4487 - acc: 0.4557\n",
      "Epoch 50/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4439 - acc: 0.4557\n",
      "Epoch 51/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4288 - acc: 0.4787\n",
      "Epoch 52/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4070 - acc: 0.4829\n",
      "Epoch 53/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.3984 - acc: 0.4725\n",
      "Epoch 54/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4144 - acc: 0.4627\n",
      "Epoch 55/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4010 - acc: 0.4676\n",
      "Epoch 56/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.4002 - acc: 0.4669\n",
      "Epoch 57/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.3980 - acc: 0.4676\n",
      "Epoch 58/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.3689 - acc: 0.4774\n",
      "Epoch 59/60\n",
      "1435/1435 [==============================] - 6s 4ms/step - loss: 1.3724 - acc: 0.4920\n",
      "Epoch 60/60\n",
      "1435/1435 [==============================] - 7s 5ms/step - loss: 1.3767 - acc: 0.4885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23867244860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "modelser = Sequential()\n",
    "\n",
    "#LSTM Layer1\n",
    "modelser.add(LSTM(32, return_sequences=True, input_shape=(75, 800)))     # returns a sequence of vectors of dimension 32\n",
    "\n",
    "#LSTM Layer2\n",
    "modelser.add(LSTM(32, return_sequences=True))                             # returns a sequence of vectors of dimension 32\n",
    "\n",
    "#LSTM Layer3\n",
    "modelser.add(LSTM(32))                                                    # return a single vector of dimension 32\n",
    "\n",
    "#Output layer\n",
    "modelser.add(Dense(8, activation='softmax'))\n",
    "\n",
    "modelser.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelser.fit(capp, labels, batch_size=128, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "modelser_json = modelser.to_json()\n",
    "with open(\"modelser.json\", \"w\") as json_file:\n",
    "    json_file.write(modelser_json)\n",
    "# serialize weights to HDF5\n",
    "modelser.save_weights(\"modelser.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('modelser.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"modelser.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n",
      "309248\n",
      "[-215 -187]\n",
      "179510\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "rate, data = scipy.io.wavfile.read(\"RECORDING.wav\")\n",
    "print (rate)\n",
    "print(len(data))\n",
    "print(data[0])\n",
    "new=[]\n",
    "for b in data:\n",
    "    b=max(b[0],b[1])\n",
    "    if b>0:\n",
    "        new.append(b)\n",
    "print(len(new))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179510,)\n"
     ]
    }
   ],
   "source": [
    "new=np.array(new)\n",
    "print(new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59755\n",
      "119755\n"
     ]
    }
   ],
   "source": [
    "l=len(new)\n",
    "l=abs(l-60000)\n",
    "l=int(l/2)\n",
    "print(l)\n",
    "new=new[59755:]\n",
    "print(len(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "new=new[0:-l]\n",
    "if len(new)==60001:\n",
    "    new=new[1:]\n",
    "print(len(new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(1, 40, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(new.shape)\n",
    "new=new.reshape(1,40,1500)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "from numpy import array\n",
    "import os\n",
    "\n",
    "path=\"C:/Users/Apurv/testfiles/\"\n",
    "e=[]\n",
    "arr=[]\n",
    "app=np.zeros([60000, 32])\n",
    "i=0\n",
    "for filename in os.listdir(path):\n",
    "    emo=int(filename[7])\n",
    "    rate, data = scipy.io.wavfile.read(\"C:/Users/Apurv/testfiles/\"+filename)\n",
    "    if data.shape[0]==n:\n",
    "        e.append(emo)\n",
    "        data = data[54688:]\n",
    "        for j in range(0,60000):\n",
    "            app[j][i]=data[j]\n",
    "        data=data.tolist()\n",
    "        arr.append(data)\n",
    "    else:\n",
    "        print(filename)\n",
    "    i=i+1\n",
    "print(len(arr))\n",
    "a=array(arr)\n",
    "x_test=app\n",
    "x_test=np.transpose(x_test)\n",
    "e=array(e)\n",
    "import sklearn\n",
    "from keras.utils import to_categorical\n",
    "y_test = []\n",
    "for i in range(0,32):\n",
    "    lab=to_categorical(e[i], 9)\n",
    "    lab=lab[1:]\n",
    "    y_test.append(lab)\n",
    "x_test = x_test.reshape(32, 75, 800)\n",
    "y_test=array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.254598617553711\n",
      "Test accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_test, np.array(y_test), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', 100*score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01268089 0.00828596 0.13168201 0.02891839 0.31100637 0.06775223\n",
      " 0.17571126 0.26396295]\n",
      "Probability assigned to each emotion class as percentage:\n",
      "\n",
      "Neutral: 1.2680886313319206\n",
      "\n",
      "Calm: 0.8285964839160442\n",
      "\n",
      "Happy: 13.168200850486755\n",
      "\n",
      "Sad: 2.891838923096657\n",
      "\n",
      "Angry: 31.10063672065735\n",
      "\n",
      "Fearful: 6.775222718715668\n",
      "\n",
      "Disgust: 17.57112592458725\n",
      "\n",
      "Surprised: 26.396295428276062\n"
     ]
    }
   ],
   "source": [
    "custom = loaded_model.predict(new)\n",
    "percent_emot = custom[0]\n",
    "print(custom[0])\n",
    "output_emot = custom[0].tolist();\n",
    "disp_output = \"Probability assigned to each emotion class as percentage:\" + \"\\n\\nNeutral: \"+ str(output_emot[0]*100)+ \"\\n\\nCalm: \"+ str(output_emot[1]*100)+ \"\\n\\nHappy: \"+ str(output_emot[2]*100)+ \"\\n\\nSad: \"+ str(output_emot[3]*100) + \"\\n\\nAngry: \"+ str(output_emot[4]*100) + \"\\n\\nFearful: \"+ str(output_emot[5]*100) + \"\\n\\nDisgust: \" +str(output_emot[6]*100 )+\"\\n\\nSurprised: \" + str(output_emot[7]*100) \n",
    "print(disp_output)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.utils\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,activation='sigmoid',batch_input_shape=(1435,1,60000)))\n",
    "model.add(Dense(9))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit(capp, labels, epochs=5, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
