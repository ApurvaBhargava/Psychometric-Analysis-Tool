{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "\n",
    "# Create an object. Zero for external camera\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "a = 0\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    a = a + 1\n",
    "    \n",
    "    # Create a frame object\n",
    "    check, frame = video.read()\n",
    "\n",
    "    #print(check)\n",
    "    #print(frame) #representing image\n",
    "\n",
    "    # Converting to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Capturing\", gray)\n",
    "\n",
    "    # For press any key to out (milliseconds)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    # For playing\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif key%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, gray)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        print(gray)\n",
    "        img_counter += 1\n",
    "    elif key == ord('q'):\n",
    "        #Q pressed\n",
    "        break\n",
    "\n",
    "print(a)\n",
    "\n",
    "# Shutdown the camera\n",
    "video.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtGui import QIcon, QFont\n",
    "\n",
    "class Example(QWidget):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "\n",
    "    def initUI(self):\n",
    "        \n",
    "        QToolTip.setFont(QFont('SansSerif', 10))\n",
    "        self.setToolTip('This is a <b>QWidget</b> widget')\n",
    "        btn = QPushButton('Button', self)\n",
    "        btn.setToolTip('This is a <b>QPushButton</b> widget')\n",
    "        btn.resize(btn.sizeHint())\n",
    "        btn.move(50, 50)\n",
    "        #w.resize(700, 700)\n",
    "        #w.move(300, 300)\n",
    "        self.setGeometry(150, 150, 1000, 700)\n",
    "        self.setWindowTitle('Psychometric Tool')\n",
    "        self.setWindowIcon(QIcon('web.png'))\n",
    "        self.show()\n",
    "\n",
    "    def closeEvent(self, event):    \n",
    "        reply = QMessageBox.question(self, 'Quit Tool?',\n",
    "            \"Are you sure to quit?\", QMessageBox.Yes | \n",
    "            QMessageBox.No, QMessageBox.No)\n",
    "\n",
    "        if reply == QMessageBox.Yes:\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = Example()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtGui import QWidget\n",
    "class MainApp(QWidget):\n",
    "    def __init__(self):\n",
    "        QWidget.__init__(self)\n",
    "        self.video_size = QSize(320, 240)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    win = MainApp()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester output\n",
      "Tester output\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import Toplevel\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "#import time\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "\n",
    "class App:\n",
    "\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='seashell4')\n",
    "\n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=2, relief=tkinter.RAISED)\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\")) \n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.FLAT, command=self.displayx)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\")) \n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\")) \n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, command=self.displayx)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\")) \n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, command=self.displayx)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "\n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED)\n",
    "        # Open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.window, self.video_source)\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tkinter.Canvas(self.left_frame, width=self.vid.width, height=self.vid.height)\n",
    "        self.canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)  \n",
    "        # Display information at the bottom of the webcam feed\n",
    "        label_header=tkinter.Label(self.left_frame, text=\"Emotion detection using webcam and microphone feed\\n\\nClick on Start button to start analysis.\\nClick on Stop button to stop analysis.\\nClick on Screenshot to start facial expression based emotion recognition.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,20))\n",
    "        #Buttons for starting and stopping video-audio analysis, and for taking a snapshot\n",
    "        btn_start=tkinter.Button(self.left_frame, text=\"Start\", width=30, command=self.displayx)\n",
    "        btn_start.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_stop=tkinter.Button(self.left_frame, text=\"Stop\", width=30, command=self.displayx)\n",
    "        btn_stop.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_snapshot=tkinter.Button(self.left_frame, text=\"Snapshot\", width=30, command=self.snapshot)\n",
    "        btn_snapshot.pack(anchor=tkinter.CENTER, pady=(5,15))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "\n",
    "        # Result to be displayed at the right of the webcam feed\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED)\n",
    "        results_lab=tkinter.Label(self.result_frame, text=\"Emotion detection using webcam and microphone feed\\n\\n::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        results_box=tkinter.Text(self.result_frame, width=100, height=40)\n",
    "        results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "\n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def displayx(self):\n",
    "        print(\"Tester output\")\n",
    "\n",
    "    def increase_brightness(self, img, value=30):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        lim = 255 - value\n",
    "        v[v > lim] = 255\n",
    "        v[v <= lim] += value\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "\n",
    "    def snapshot(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            # load json and create model\n",
    "            json_file = open('model.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "            # load weights into new model\n",
    "            loaded_model.load_weights(\"model.h5\")\n",
    "            # Face detection and FER\n",
    "            face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            snapshot = self.increase_brightness(frame, value=40)\n",
    "            gray = cv2.cvtColor(snapshot, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            print(faces)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = gray[y:y+h, x:x+w]\n",
    "                img = cv2.resize(roi,(48,48))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis = 0)\n",
    "                x /= 255\n",
    "                custom = loaded_model.predict(x)\n",
    "                percent_emot = custom[0]\n",
    "                print(custom[0])\n",
    "\n",
    "            #cv2.imwrite(\"frame-\" + time.strftime(\"%d-%m-%Y-%H-%M-%S\") + \".jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "\n",
    "        if ret:\n",
    "            self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "\n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "    def screen_two(self):\n",
    "        self.window.withdraw()\n",
    "        self.newWindow = tkinter.Toplevel(self.window)\n",
    "        Screen2(self.newWindow, self.window) #argumen1 is itself, argument2 is parent\n",
    "\n",
    "class Screen2():\n",
    "\n",
    "    def __init__(self, window, master):\n",
    "        self.window = window\n",
    "        self.master = master\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='seashell4')\n",
    "        \n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED)\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\")) \n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\")) \n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.FLAT, command=self.displayx)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\")) \n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, command=self.displayx)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\")) \n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, command=self.displayx)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED)\n",
    "        eimg = PIL.ImageTk.PhotoImage(PIL.Image.open(\"survival.jpg\"))\n",
    "        image_label = tkinter.Label(self.left_frame, image=eimg, width=800, height=560)\n",
    "        image_label.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #canvas = tkinter.Canvas(self.left_frame, bd=0, width=500, height=400)\n",
    "        #canvas.create_image(10, 10, image=eimg, anchor=tkinter.CENTER)\n",
    "        #canvas.config(scrollregion=canvas.bbox(tkinter.ALL))\n",
    "        #canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #Display information below image\n",
    "        label_header=tkinter.Label(self.left_frame, text=\"Picture description based test\\n\\nClick on Next button to go to next picture.\\nClick on Previous button to go to previous picture.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        #Buttons for navigating through pictures/images\n",
    "        btn_prev=tkinter.Button(self.left_frame, text=\"<< Previous\", width=20, height=3, command=self.displayx)\n",
    "        btn_prev.pack(side=tkinter.LEFT, padx=(10,10), pady=(10,10))\n",
    "        btn_next=tkinter.Button(self.left_frame, text=\"Next >>\", width=20, height=3, command=self.displayx)\n",
    "        btn_next.pack(side=tkinter.RIGHT, padx=(10,10), pady=(10,10))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "        \n",
    "        # Result to be displayed at the right of the webcam feed\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED)\n",
    "        ans_lab=tkinter.Label(self.result_frame, text=\"Picture description based test\")\n",
    "        ans_lab.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,5))\n",
    "        ans_box=tkinter.Text(self.result_frame, width=100, height=18)\n",
    "        ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        btn_submit=tkinter.Button(self.result_frame, text=\"Submit\", width=20, command=self.displayx)\n",
    "        btn_submit.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        results_lab=tkinter.Label(self.result_frame, text=\"::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,5))\n",
    "        results_box=tkinter.Text(self.result_frame, width=100, height=19)\n",
    "        results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "        \n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_exit)\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.withdraw()\n",
    "        self.master.deiconify()\n",
    "        self.master.wm_state('zoomed')\n",
    "\n",
    "    def on_exit(self):\n",
    "        self.window.destroy()\n",
    "        self.master.destroy()        \n",
    "\n",
    "class MyVideoCapture:\n",
    "    def __init__(self, parent, video_source=0):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280);\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720);\n",
    "        # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "if __name__ == '__main__':\n",
    "    App(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread('surprise.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    #img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),1)\n",
    "    roi = gray[y:y+h, x:x+w]\n",
    "    print(roi)\n",
    "    cv2.imwrite(\"roi.png\", roi)\n",
    "#cv2.imshow('img',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
