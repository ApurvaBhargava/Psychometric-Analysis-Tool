{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "stop\n",
      "\n",
      "\n",
      "Loaded model from disk\n",
      "141832\n",
      "(1, 100000)\n",
      "[2.90978569e-05 3.63911130e-02 1.05347885e-02 2.64510072e-05\n",
      " 7.82807767e-01 1.70189396e-01 2.13739095e-05]\n",
      "Probability assigned to each emotion class as percentage for SER:\n",
      "\n",
      "Neutral: 0.002909785689553246\n",
      "\n",
      "Calm: 3.6391112953424454\n",
      "\n",
      "Happy: 1.0534788481891155\n",
      "\n",
      "Sad: 0.002645100721565541\n",
      "\n",
      "Angry: 78.28077673912048\n",
      "\n",
      "Fearful: 17.018939554691315\n",
      "\n",
      "Disgust: 0.002137390947609674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19310266 0.07174724 0.7351501 ]\n",
      "Pics Schema exists\n",
      "\n",
      "10\n",
      "10 1\n",
      "changed\n",
      "Pics Schema exists\n",
      "\n",
      "10\n",
      "10 2\n",
      "changed\n",
      "[0.16520108 0.11527742 0.71952146]\n",
      "3\n",
      "How would you describe yourself?\n",
      "3\n",
      "How would you respond if given the responsibility to handle a task, that is beyond your skill-set,  unexpectedly?\n",
      "3\n",
      "How would you describe yourself?\n",
      "2 I am confident, determined, diligent, hard working, responsible, sincere, ambitious, honest, driven, friendly, sociable, optimistic, opportunistic.\n",
      "I am confident, diligent and honest.\n",
      " i am confid , determin , dilig , hard work , respons , sincer , ambiti , honest , driven , friend , sociabl , optimist , opportunist .\n",
      " i am confid , dilig and honest .\n",
      "Pics Schema exists\n",
      "\n",
      "yo\n",
      "Pics Schema exists\n",
      "\n",
      "11\n",
      "11 1\n",
      "changed\n",
      "Pics Schema exists\n",
      "\n",
      "11\n",
      "11 11\n",
      "changed\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import Toplevel\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "#import time\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from PIL import ImageFilter, ImageEnhance\n",
    "from keras.models import model_from_json\n",
    "from tkinter import filedialog\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os.path\n",
    "from os import listdir, getcwd\n",
    "from IPython.core.display import Image\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import time\n",
    "#import keyboard\n",
    "import threading\n",
    "\n",
    "class App:\n",
    "\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(True, True)\n",
    "        self.window.configure(background='honeydew4')\n",
    "\n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=2, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.FLAT, bg=\"honeydew3\", command=self.displayx)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "\n",
    "        self.left_frame = tkinter.Frame(window, bd=3, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        # Open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.window, self.video_source)\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tkinter.Canvas(self.left_frame, width=self.vid.width, height=self.vid.height)\n",
    "        self.canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)  \n",
    "        # Display information at the bottom of the webcam feed\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"honeydew2\", text=\"Emotion detection using webcam and microphone feed\\n\\nClick on Start button to start analysis.\\nClick on Stop button to stop analysis.\\nClick on Screenshot to start facial expression based emotion recognition.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,20))\n",
    "        #Buttons for starting and stopping video-audio analysis, and for taking a snapshot\n",
    "        btn_start=tkinter.Button(self.left_frame, text=\"Start\", width=30, bg=\"honeydew3\" , command=lambda:self.start_recording())\n",
    "        btn_start.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_stop=tkinter.Button(self.left_frame, text=\"Stop\", width=30, bg=\"honeydew3\" , command=lambda:self.stop_recording())\n",
    "        btn_stop.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_snapshot=tkinter.Button(self.left_frame, text=\"Snapshot\", width=30, bg=\"honeydew3\", command=self.snapshot)\n",
    "        btn_snapshot.pack(anchor=tkinter.CENTER, pady=(5,15))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "\n",
    "        # Result to be displayed at the right of the webcam feed\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"honeydew2\", text=\"Emotion detection using webcam and microphone feed\\n\\n::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        self.results_box=tkinter.Text(self.result_frame, width=100, height=40, bg=\"honeydew3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "\n",
    "        self.flag = 1\n",
    "        \n",
    "        self.imgcapCount = 0\n",
    "        \n",
    "        self.FORMAT=pyaudio.paInt16\n",
    "        self.CHANNELS=2\n",
    "        self.RATE=44100\n",
    "        self.CHUNK=1024\n",
    "        #RECORD_SECONDS = 10\n",
    "        self.FILE_NAME=\"RECORDING.wav\"\n",
    "        self.audio=pyaudio.PyAudio() #instantiate the pyaudio\n",
    "        #recording prerequisites\n",
    "        self.stream=self.audio.open(format=self.FORMAT,channels=self.CHANNELS, \n",
    "                          rate=self.RATE,\n",
    "                          input=True,\n",
    "                          frames_per_buffer=self.CHUNK)\n",
    "        #starting recording\n",
    "        self.frames2=[]\n",
    "        self.isrecording=False\n",
    "        \n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def displayx(self):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        print(\"Tester output\")\n",
    "\n",
    "        \n",
    "    def start_recording(self):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        self.isrecording = True\n",
    "        t = threading.Thread(target=self.record)\n",
    "        t.start()\n",
    "        s = threading.Thread(target=self.capture)\n",
    "        s.start()\n",
    "\n",
    "    def stop_recording(self):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        self.isrecording = False\n",
    "        print(\"stop\")\n",
    "        #end of recording\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.audio.terminate()\n",
    "        #writing to file\n",
    "        wavfile=wave.open(self.FILE_NAME,'wb')\n",
    "        wavfile.setnchannels(self.CHANNELS)\n",
    "        wavfile.setsampwidth(self.audio.get_sample_size(self.FORMAT))\n",
    "        wavfile.setframerate(self.RATE)\n",
    "        wavfile.writeframes(b''.join(self.frames2))#append frames recorded to file\n",
    "        wavfile.close()\n",
    "        \n",
    "        # load json and create model\n",
    "        json_file = open('modelser.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"modelser.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "        import numpy as np\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "        import scipy.io.wavfile\n",
    "        rate, data = scipy.io.wavfile.read(\"RECORDING.wav\")\n",
    "        #print (rate)\n",
    "        #print(len(data))\n",
    "        #print(data[0])\n",
    "        new=[]\n",
    "        for b in data:\n",
    "            b=max(b[0],b[1])\n",
    "            if b>0:\n",
    "                new.append(b)\n",
    "        print(len(new))\n",
    "        new=np.array(new)\n",
    "        l=len(new)\n",
    "        c=int(l/100000)\n",
    "        left=len(new)-(c*100000)\n",
    "        rec=[]\n",
    "        i=0\n",
    "        for i in range(0,c):\n",
    "            rec.append(new[100000*i:100000*(i+1)])\n",
    "\n",
    "        if left>=70000:\n",
    "            j=new[(c*100000):(c*100000)+left]\n",
    "            l=len(j)\n",
    "            l=100000-l\n",
    "            for k in range(0,l):\n",
    "                j=np.append(j,new[(c*100000)+k])\n",
    "            c=c+1\n",
    "            rec.append(j)\n",
    "        rec=np.array(rec)    \n",
    "        print(rec.shape)\n",
    "\n",
    "        summ=np.zeros([7])\n",
    "        for i in range(0,c):\n",
    "            find=rec[i]\n",
    "            find=find.reshape(1,10,10000)\n",
    "            custom = loaded_model.predict(find)\n",
    "            percent_emot = custom[0]\n",
    "            output_emot = custom[0].tolist()\n",
    "            for k in range(0,7):\n",
    "                summ[k]=summ[k]+(output_emot[k])\n",
    "\n",
    "            #disp_output = \"Probability assigned to each emotion class as percentage:\" + \"\\n\\nNeutral: \"+ str(output_emot[0]*100)+ \"\\n\\nCalm: \"+ str(output_emot[1]*100)+ \"\\n\\nHappy: \"+ str(output_emot[2]*100)+ \"\\n\\nSad: \"+ str(output_emot[3]*100) + \"\\n\\nAngry: \"+ str(output_emot[4]*100) + \"\\n\\nFearful: \"+ str(output_emot[5]*100) + \"\\n\\nDisgust: \" +str(output_emot[6]*100 ) \n",
    "            #print(disp_output)\n",
    "        for k in range(0,7):\n",
    "            summ[k]=summ[k]/c\n",
    "        print(summ)\n",
    "        disp = \"Probability assigned to each emotion class as percentage for SER:\" + \"\\n\\nNeutral: \"+ str(summ[0]*100)+ \"\\n\\nCalm: \"+ str(summ[1]*100)+ \"\\n\\nHappy: \"+ str(summ[2]*100)+ \"\\n\\nSad: \"+ str(summ[3]*100) + \"\\n\\nAngry: \"+ str(summ[4]*100) + \"\\n\\nFearful: \"+ str(summ[5]*100) + \"\\n\\nDisgust: \" +str(summ[6]*100 ) \n",
    "        print(disp)\n",
    "        \n",
    "        #self.results_box.config(state='normal')\n",
    "        self.results_box.insert('end', disp)\n",
    "        #self.results_box.config(state='disable')\n",
    "        \n",
    "        # load json and create model\n",
    "        json_file = open('modelg9.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"model_weightsg9.h5\")\n",
    "        final_emot = [0, 0, 0, 0, 0, 0, 0]\n",
    "        for i in range(0, self.imgcapCount):\n",
    "            filename = \"imgcap\" + str(i) + \".png\"\n",
    "            img = image.load_img(filename, grayscale=True)\n",
    "            img = ImageEnhance.Brightness(img).enhance(3)\n",
    "            img = img.filter(ImageFilter.GaussianBlur(3))\n",
    "            img= img.resize((48,48))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis = 0)\n",
    "            custom = loaded_model.predict(x)\n",
    "            output_emot = custom[0].tolist()\n",
    "            for k in range(0, 7):\n",
    "                final_emot[k] += output_emot[k]\n",
    "        for k in range(0, 7):\n",
    "            final_emot[k] /= self.imgcapCount\n",
    "        disp = \"\\n\\nProbability assigned to each emotion class as percentage for FER:\" + \"\\n\\nAngry: \"+ str(final_emot[0]*100)+ \"\\n\\nDisgust: \"+ str(final_emot[1]*100)+ \"\\n\\nFear: \"+ str(final_emot[2]*100)+ \"\\n\\nHappy: \"+ str(final_emot[3]*100) + \"\\n\\nSad: \"+ str(final_emot[4]*100) + \"\\n\\nSurprised: \"+ str(final_emot[5]*100) + \"\\n\\nNeutral: \" +str(final_emot[6]*100 ) \n",
    "        self.results_box.insert('end', disp)\n",
    "        \n",
    "    def record(self):\n",
    "        self.FORMAT=pyaudio.paInt16\n",
    "        self.CHANNELS=2\n",
    "        self.RATE=44100\n",
    "        self.CHUNK=1024\n",
    "        #RECORD_SECONDS = 10\n",
    "        self.FILE_NAME=\"RECORDING.wav\"\n",
    "\n",
    "        self.audio=pyaudio.PyAudio() #instantiate the pyaudio\n",
    "        #recording prerequisites\n",
    "        self.stream=self.audio.open(format=self.FORMAT,channels=self.CHANNELS, \n",
    "                          rate=self.RATE,\n",
    "                          input=True,\n",
    "                          frames_per_buffer=self.CHUNK)\n",
    "        #starting recording\n",
    "        self.frames2=[]\n",
    "        while self.isrecording==1:\n",
    "            data=self.stream.read(self.CHUNK)\n",
    "            data_chunk=array('h',data)\n",
    "            vol=max(data_chunk)\n",
    "            if(vol>=500):\n",
    "                #print(\"something said\")\n",
    "                self.frames2.append(data)\n",
    "            else:\n",
    "                print(\"nothing\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    def capture(self):\n",
    "        self.imgcapCount=0\n",
    "        while self.isrecording==1:\n",
    "            ret, frame = self.vid.get_frame()\n",
    "            if ret:\n",
    "                cv2.imwrite(\"imgcap\" + str(self.imgcapCount) + \".png\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "                self.imgcapCount+=1\n",
    "                time.sleep(3)\n",
    "        \n",
    "    def increase_brightness(self, img, value=30):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        lim = 255 - value\n",
    "        v[v > lim] = 255\n",
    "        v[v <= lim] += value\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "\n",
    "    def snapshot(self):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            # load json and create model\n",
    "            json_file = open('modelg9.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "            # load weights into new model\n",
    "            loaded_model.load_weights(\"model_weightsg9.h5\")\n",
    "            cv2.imwrite(\"framesnap.png\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "            img = image.load_img(\"framesnap.png\", grayscale=True)\n",
    "            img = ImageEnhance.Brightness(img).enhance(3)\n",
    "            img = img.filter(ImageFilter.GaussianBlur(3))\n",
    "            img= img.resize((48,48))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis = 0)\n",
    "            custom = loaded_model.predict(x)\n",
    "            percent_emot = custom[0]\n",
    "            output_emot = custom[0].tolist()\n",
    "            disp_output = \"Probability assigned to each emotion class as percentage for FER:\", \"\\n\\nAngry: \", output_emot[0]*100, \"\\n\\nDisgust: \", output_emot[1]*100, \"\\n\\nFear: \", output_emot[2]*100, \"\\n\\nHappy: \", output_emot[3]*100, \"\\n\\nSad: \", output_emot[4]*100, \"\\n\\nSurprise: \", output_emot[5]*100, \"\\n\\nNeutral: \", output_emot[6]*100\n",
    "            self.results_box.insert(\"1.0\", disp_output)\n",
    "            '''\n",
    "            # Face detection and FER\n",
    "            face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            snapshot = self.increase_brightness(frame, value=40)\n",
    "            gray = cv2.cvtColor(snapshot, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            print(faces)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = gray[y:y+h, x:x+w]\n",
    "                img = cv2.resize(roi,(48,48))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis = 0)\n",
    "                x /= 255\n",
    "                custom = loaded_model.predict(x)\n",
    "                percent_emot = custom[0]\n",
    "                #print(custom[0])\n",
    "                output_emot = custom[0].tolist();\n",
    "                #print(output_emot[0])\n",
    "                disp_output = \"Probability assigned to each emotion class as percentage for FER:\", \"\\n\\nAngry: \", output_emot[0]*100, \"\\n\\nDisgust: \", output_emot[1]*100, \"\\n\\nFear: \", output_emot[2]*100, \"\\n\\nHappy: \", output_emot[3]*100, \"\\n\\nSad: \", output_emot[4]*100, \"\\n\\nSurprise: \", output_emot[5]*100, \"\\n\\nNeutral: \", output_emot[6]*100\n",
    "                #self.results_box.config(state='normal')\n",
    "                self.results_box.insert(\"1.0\", disp_output)\n",
    "                #self.results_box.config(state='disable')\n",
    "            #cv2.imwrite(\"frame-\" + time.strftime(\"%d-%m-%Y-%H-%M-%S\") + \".jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "            '''\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        \n",
    "        if ret:\n",
    "            self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "\n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "\n",
    "class MyVideoCapture:\n",
    "    def __init__(self, parent, video_source=0):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280);\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720);\n",
    "        # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    def detect(self, gray, frame):\n",
    "        # Now get the tuples that detect the faces using above cascade\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        # Now iterate over the faces and detect eyes\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            canvas = self.detect(gray, frame)\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "if __name__ == '__main__':\n",
    "    App(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import math\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Splitter(object):\n",
    "    def __init__(self):\n",
    "        self.nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    def split(self, text):\n",
    "        sentences = self.nltk_splitter.tokenize(text)\n",
    "        tokenized_sentences = [self.nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        return tokenized_sentences\n",
    "\n",
    "class POSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def pos_tag(self, sentences):\n",
    "        pos = [nltk.pos_tag(sentence) for sentence in sentences]\n",
    "        pos = [[(word, word, [postag]) for (word, postag) in sentence] for sentence in pos]\n",
    "        return pos\n",
    "\n",
    "class Screen2():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='SlateGray4')\n",
    "        \n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.FLAT, bg=\"SlateGray3\", command=self.displayx)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        self.global_picid=1\n",
    "        self.img=\"survival.jpg\"\n",
    "        self.eimg = PIL.ImageTk.PhotoImage(PIL.Image.open(self.img))\n",
    "        self.image_label = tkinter.Label(self.left_frame, image=self.eimg, width=800, height=560, bg=\"SlateGray2\")\n",
    "        self.image_label.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #canvas = tkinter.Canvas(self.left_frame, bd=0, width=500, height=400)\n",
    "        #canvas.create_image(10, 10, image=eimg, anchor=tkinter.CENTER)\n",
    "        #canvas.config(scrollregion=canvas.bbox(tkinter.ALL))\n",
    "        #canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #Display information below image\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"SlateGray2\", text=\"Picture description based test\\n\\nClick on Next button to go to next picture.\\nClick on Previous button to go to previous picture.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        #Buttons for navigating through pictures/images\n",
    "        btn_prev=tkinter.Button(self.left_frame, text=\"<< Previous\", width=20, height=3, bg=\"SlateGray3\", command=lambda:self.extract_picture(1))\n",
    "        btn_prev.pack(side=tkinter.LEFT, pady=(10,10))\n",
    "        btn_next=tkinter.Button(self.left_frame, text=\"Next >>\", width=20, height=3, bg=\"SlateGray3\", command=lambda:self.extract_picture(2))\n",
    "        btn_next.pack(side=tkinter.RIGHT, pady=(10,10))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "        \n",
    "        # Result to be displayed at the right of the image\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        ans_lab=tkinter.Label(self.result_frame, bg=\"SlateGray2\", text=\"Picture description based test\")\n",
    "        ans_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.ans_box=tkinter.Text(self.result_frame, width=100, height=18, bg=\"SlateGray3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        btn_submit=tkinter.Button(self.result_frame, text=\"Submit\", width=20, bg=\"SlateGray3\", command=lambda:self.submit_text(self.ans_box.get(\"1.0\",\"e-1c\")))\n",
    "        btn_submit.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"SlateGray2\", text=\"::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.results_box=tkinter.Text(self.result_frame, width=100, height=19, bg=\"SlateGray3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "        \n",
    "        self.splitter = Splitter()\n",
    "        self.tok = WordPunctTokenizer()\n",
    "        self.postagger = POSTagger()\n",
    "        self.pat1 = r'@[A-Za-z0-9]+'\n",
    "        self.pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "        self.combined_pat = r'|'.join((self.pat1, self.pat2))\n",
    "        \n",
    "        self.window.mainloop()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def extract_picture(self,index):\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = self.create_or_open_dbpics('picture_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        pic_id=self.global_picid\n",
    "        \n",
    "        \n",
    "        cur.execute(\"SELECT MAX(ID) FROM PICTURES\")\n",
    "        for row in cur:\n",
    "            print(row[0])\n",
    "            max_id=row[0]\n",
    "        print(max_id,pic_id)\n",
    "        if pic_id==1 and index==1:\n",
    "            pid=max_id\n",
    "            \n",
    "        elif pic_id==max_id and index==2:\n",
    "            pid=1\n",
    "            \n",
    "        elif index==1:\n",
    "            pid=pic_id-1\n",
    "            \n",
    "        else:\n",
    "            pid=pic_id+1\n",
    "            \n",
    "        self.global_picid=pid    \n",
    "        cur.execute(\"SELECT FILENAME,PICTURE FROM PICTURES WHERE ID = ?\",(pid,))\n",
    "        for row in cur:    \n",
    "            name=row[0]\n",
    "            \n",
    "        with open(name, 'rb') as input_file:\n",
    "            ablob = input_file.read()\n",
    "            #base=os.path.basename(pic)\n",
    "            #afile, ext = os.path.splitext(base)\n",
    "        \n",
    "        #filename = afile + ext\n",
    "        with open(name, 'wb') as output_file:\n",
    "            output_file.write(ablob)\n",
    "            \n",
    "        #self.eimg.destroy()    \n",
    "        #self.image_label.destroy()\n",
    "        #image = Image.open(filename)\n",
    "        self.img=name\n",
    "        #photo = ImageTk.PhotoImage(image)\n",
    "        self.eimg= PIL.ImageTk.PhotoImage(PIL.Image.open(name))\n",
    "        #label = Label(root,image=eimg)\n",
    "        #self.image_label=tkinter.Label(self.left_frame, image=self.eimg, width=150, height=90, bg=\"SlateGray2\")\n",
    "        #self.image_label.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        self.image_label.configure(image=None)\n",
    "        self.image_label.configure(image=self.eimg)\n",
    "        #self.left_frame.update_idletasks()\n",
    "        print('changed')\n",
    "        #label.image = photo # keep a reference!\n",
    "        #label.pack()\n",
    "        return\n",
    "\n",
    "        \n",
    "    def create_or_open_dbpics(self,db_file):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists PICTURES(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            FILENAME STRING,\n",
    "            PICTURE BLOB);'''\n",
    "            conn.execute(sql)\n",
    "        else:\n",
    "            print ('Pics Schema exists\\n')\n",
    "        return conn\n",
    "\n",
    "    \n",
    "    def submit_text(self, ans):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        #print(ans)\n",
    "        # send this ans for sentiment analysis\n",
    "        createfeed=pd.read_csv('sentimentfinalterm_freq_tfidf.csv',index_col=0)\n",
    "        feature_values=[0,0,0]\n",
    "        str_result = self.text_cleaner(ans)\n",
    "        words= str_result.split()\n",
    "        for j in range(0, len(words)):\n",
    "            try:\n",
    "                feature_values = np.add(feature_values,[createfeed.loc[words[j]][0],createfeed.loc[words[j]][1],createfeed.loc[words[j]][2]])\n",
    "            except:\n",
    "                continue\n",
    "        #self.results_box.config(state='normal')\n",
    "        try:\n",
    "            feature_values = feature_values.tolist()\n",
    "            feature_values = np.array(feature_values)\n",
    "            final_feature_values = []\n",
    "            final_feature_values.append(feature_values)\n",
    "            final_feature_values = np.array(final_feature_values)\n",
    "            # load json and create model\n",
    "            json_file = open('modelsentif.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "            # load weights into new model\n",
    "            loaded_model.load_weights(\"modelsentif.h5\")\n",
    "            # Predict sentiment class using model\n",
    "            custom = loaded_model.predict(final_feature_values)\n",
    "            output_emot = custom[0].tolist();\n",
    "            disp_output = \"Probability assigned to each sentiment class as percentage:\", \"\\n\\nNegative: \", output_emot[0]*100, \"\\n\\nNeutral: \", output_emot[1]*100, \"\\n\\nPositive: \", output_emot[2]*100\n",
    "            self.results_box.insert(\"1.0\", disp_output)\n",
    "            print(custom[0])\n",
    "        except:\n",
    "            self.results_box.insert(\"1.0\", \"A longer description is required to get accurate sentiment estimation.\")\n",
    "        #self.results_box.config(state='disabled')\n",
    "            \n",
    "    \n",
    "    def text_cleaner(self,text):\n",
    "        negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "        neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "        soup = BeautifulSoup(text, 'lxml')\n",
    "        souped = soup.get_text()\n",
    "        stripped = re.sub(self.combined_pat, '', souped)\n",
    "        try:\n",
    "            clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        except:\n",
    "            clean = stripped\n",
    "        lower_case=\"\"\n",
    "        for i in range(0,len(clean)):\n",
    "            if text[i].isalpha():\n",
    "                lower_case=lower_case+text[i].lower()\n",
    "            elif text[i].isdigit():\n",
    "                lower_case=lower_case\n",
    "            else:\n",
    "                lower_case=lower_case+text[i]\n",
    "        neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "        words = [x for x  in self.tok.tokenize(letters_only) if len(x) > 1]\n",
    "        forpos= \" \".join(words).strip()\n",
    "        splitted_sentences = self.splitter.split(forpos)\n",
    "        pos_tagged_sentences = self.postagger.pos_tag(splitted_sentences)\n",
    "        altered_text=\"\"\n",
    "        for sentences in pos_tagged_sentences:\n",
    "            for word in sentences:\n",
    "                v=word[2]\n",
    "                for val in v:\n",
    "                    if (val==\"JJ\" or val==\"JJR\" or val==\"JJS\" or val==\"VB\" or val==\"VBD\" or val==\"VBG\"\n",
    "                        or val==\"VBN\" or val==\"VBP\" or val==\"VBZ\" or val==\"RB\" or val==\"RBR\" or val==\"RBS\" ):\n",
    "                        altered_text=altered_text+word[0]+\" \"\n",
    "        return altered_text\n",
    "\n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Screen3():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='LemonChiffon4')\n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.FLAT, bg=\"LemonChiffon3\", command=self.displayx)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.global_quesid=1\n",
    "        #ques_to_display=\"Which city is known as the PITAL NAGRI\"\n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        ques_label = tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Question\")\n",
    "        ques_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ques_box=tkinter.Text(self.left_frame, width=100, height=14, bg=\"LemonChiffon3\")\n",
    "        self.ques_box.insert(\"1.0\", \"Click on Next to display question.\")\n",
    "        self.ques_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        ans_label = tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Answer\")\n",
    "        ans_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ans_box=tkinter.Text(self.left_frame, width=100, height=14, bg=\"LemonChiffon3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Situational judgement based test\\n\\nClick on Next button to go to next question.\\nClick on Previous button to go to previous question.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        #Buttons for displaying answer and navigating through questions\n",
    "        #btn_display=tkinter.Button(self.left_frame, text=\"Display answer\", width=20, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(self.ques_box.get(\"1.0\",\"end-1c\"),1))\n",
    "        #btn_display.pack(anchor=tkinter.CENTER, pady=(5,10))\n",
    "        btn_prev=tkinter.Button(self.left_frame, text=\"<< Previous\", width=20, height=2, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(1))\n",
    "        btn_prev.pack(side=tkinter.LEFT, pady=(10,10))\n",
    "        btn_next=tkinter.Button(self.left_frame, text=\"Next >>\", width=20, height=2, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(2))\n",
    "        btn_next.pack(side=tkinter.RIGHT, pady=(10,10))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "        \n",
    "        # Result to be displayed at the right\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        ans_lab=tkinter.Label(self.result_frame, bg=\"LemonChiffon2\", text=\"Situational judgement based test\")\n",
    "        ans_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.answ_box=tkinter.Text(self.result_frame, width=100, height=18, bg=\"LemonChiffon3\")\n",
    "        self.answ_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        btn_submit=tkinter.Button(self.result_frame, text=\"Submit\", width=20, bg=\"LemonChiffon3\", command=lambda:self.show_exp_answer_submit_given_ans(self.answ_box.get('1.0','end-1c')))\n",
    "        btn_submit.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"LemonChiffon2\", text=\"::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.results_box=tkinter.Text(self.result_frame, width=100, height=19, bg=\"LemonChiffon3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "        \n",
    "        self.window.mainloop()\n",
    "    \n",
    "        \n",
    "        \n",
    "    def extract_quesans(self,index):\n",
    "        self.answ_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ques_box.delete(\"1.0\", 'end-1c')\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = sqlite3.connect('quesans_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        qid=self.global_quesid\n",
    "        '''cur.execute(\"SELECT ID FROM QUESANS WHERE ID=?\", (qid,))\n",
    "        for row in cur:   \n",
    "            print(row[0])\n",
    "            qid=row[0]\n",
    "        '''\n",
    "        cur.execute(\"SELECT MAX(ID) FROM QUESANS\")\n",
    "        for row in cur:\n",
    "            print(row[0])\n",
    "            max_id=row[0]\n",
    "        \n",
    "        if qid==1 and index==1:\n",
    "            aid=max_id\n",
    "            \n",
    "        elif qid==1 and index==2:\n",
    "            aid=qid+1\n",
    "            \n",
    "        elif qid==max_id and index==2:\n",
    "            aid=1\n",
    "            \n",
    "        elif qid==max_id and index==1:\n",
    "            aid=qid-1\n",
    "            \n",
    "        elif index==1:\n",
    "            aid=qid-1\n",
    "            \n",
    "        else:\n",
    "            aid=qid+1\n",
    "        self.global_quesid=aid    \n",
    "        cur.execute(\"SELECT ID,QUES FROM QUESANS WHERE ID = ?\",(aid,))\n",
    "        new_qid,new_ques = cur.fetchone()\n",
    "        for r in cur:\n",
    "            print(r[0])\n",
    "            print(r[1])\n",
    "        print(new_ques)\n",
    "        self.ques_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ques_box.insert(\"1.0\",new_ques)\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.answ_box.delete(\"1.0\", 'end-1c')\n",
    "    \n",
    "    \n",
    "    def show_exp_answer_submit_given_ans(self,given_ans):\n",
    "        self.results_box.config(state='normal')\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = sqlite3.connect('quesans_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute(\"SELECT MAX(ID) FROM QUESANS\")\n",
    "        for row in cur:\n",
    "            max_id=row[0]\n",
    "        qid=self.global_quesid\n",
    "        cur.execute(\"SELECT ANS FROM QUESANS WHERE ID=?\", (qid,))\n",
    "        for row in cur:   \n",
    "            exp_ans=row[0]\n",
    "        \n",
    "        print(qid,exp_ans)\n",
    "        self.ans_box.insert(\"1.0\",exp_ans)\n",
    "        print(given_ans)\n",
    "        \n",
    "        # similarity check\n",
    "        responses = []\n",
    "        responses.append(\"\")\n",
    "        responses.append(\"\")\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        \n",
    "        one=\"\"\n",
    "        two=\"\"\n",
    "        sentences = nltk_splitter.tokenize(exp_ans)\n",
    "        tokenized_sentences = [nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        for word in tokenized_sentences[0]:\n",
    "            word = (stemmer.stem(word))\n",
    "            one=one+\" \"+word\n",
    "        print(one)    \n",
    "\n",
    "        sentences = nltk_splitter.tokenize(given_ans)\n",
    "        tokenized_sentences = [nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        for word in tokenized_sentences[0]:\n",
    "            word = (stemmer.stem(word))\n",
    "            two=two+\" \"+word\n",
    "        print(two)\n",
    "        \n",
    "        responses[0]=one\n",
    "        responses[1]=two\n",
    "        \n",
    "        #responses.append(stemmer.stem(exp_ans))\n",
    "        #responses.append(stemmer.stem(given_ans))\n",
    "        \n",
    "        score = self.scaled_score(responses)\n",
    "        \n",
    "        disp_results = \"Similarity measures:\", \"\\n\\nThe 1-gram cosine similarity of the expected and given answer is \", self.cosine_sim(responses)[0], \"\\n\\nThe 2-gram cosine similarity of the expected and given answer is \", self.cosine_sim(responses)[1],\"\\n\\nThe jaccard similarity of the expected and given answer is \", self.jaccard_sim(responses[0], responses[1])\n",
    "        disp_score = \"\\n\\nThe overall score out of 100 is \", score\n",
    "        \n",
    "        try:\n",
    "            self.results_box.insert(\"1.0\", disp_results)\n",
    "            #if self.cosine_sim(responses) > 0.3:\n",
    "            #    self.results_box.insert(\"end\", \"\\n\\nThe cosine similarity is greater than 0.2, which implies that the two responses have a good degree of similarity\")\n",
    "            #if self.jaccard_sim(responses[0], responses[1]) > 0.2:\n",
    "            #    self.results_box.insert(\"end\", \"\\n\\nThe jaccard similarity is greater than 0.1, which implies that the two responses share a lot of similar words.\")\n",
    "            self.results_box.insert(\"end\", disp_score)\n",
    "        except:\n",
    "            self.results_box.insert(\"1.0\", \"Response cannot be compared\")\n",
    "        #self.results_box.config(state='disabled')\n",
    "        #print(self.cosine_sim(responses))\n",
    "        #print(self.jaccard_sim(responses[0], responses[1]))\n",
    "        \n",
    "    def cosine_sim(self, strs):\n",
    "        cossim= []\n",
    "        for i in range(1,3):\n",
    "            vectorizer = CountVectorizer(strs, stop_words = {'a', 'an', 'the'}, ngram_range=(i,i))\n",
    "            vectorizer.fit(strs)\n",
    "            vectors = vectorizer.transform(strs).toarray()\n",
    "            cossim.append(cosine_similarity(vectors)[0][1])\n",
    "        return cossim\n",
    "    \n",
    "    def jaccard_sim(self, str1, str2):\n",
    "        a = set(str1.split())\n",
    "        b = set(str2.split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    \n",
    "    def scaled_score(self, strs):\n",
    "        cossim = self.cosine_sim(strs)\n",
    "        score = cossim[0]*60 + cossim[1]*16 + self.jaccard_sim(strs[0], strs[1])*24\n",
    "        if(cossim[1]>=0.1 and cossim[1]<=0.2):\n",
    "            score += 3\n",
    "        elif(cossim[1]>0.2 and cossim[1]<=0.4):\n",
    "            score += 6\n",
    "        elif(cossim[1]>0.4 and cossim[1]<=0.6):\n",
    "            score += 6\n",
    "        elif(cossim[1]>0.6 and cossim[1]<=0.8):\n",
    "            score += 3\n",
    "        elif(cossim[1]>0.8):\n",
    "            score += 16 * (1 - cossim[1])\n",
    "        return score\n",
    "    \n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os.path\n",
    "from os import listdir, getcwd\n",
    "from IPython.core.display import Image\n",
    "\n",
    "class Screen4():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='azure4')\n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"azure2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.FLAT, bg=\"azure3\", command=self.displayx)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.SUNKEN, bg=\"azure2\")\n",
    "        ques_label = tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Enter question to be submitted\")\n",
    "        ques_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ques_box=tkinter.Text(self.left_frame, width=100, height=15, bg=\"azure3\")\n",
    "        self.ques_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        ans_label = tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Enter answer for the question\")\n",
    "        ans_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ans_box=tkinter.Text(self.left_frame, width=100, height=15, bg=\"azure3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,2))\n",
    "        btn_submit1=tkinter.Button(self.left_frame, text=\"Submit Q/A\", width=20, height=2, bg=\"azure3\",\n",
    "                                   command=lambda:self.create_or_open_dbtext_and_insert(\"quesans_db.sqlite\", self.ques_box.get('1.0',\"end-1c\"), self.ans_box.get('1.0',\"end-1c\")))\n",
    "        btn_submit1.pack(anchor=tkinter.CENTER, pady=(10,15))\n",
    "        image_label=tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Select image(s) to be submitted\")\n",
    "        image_label.pack(anchor=tkinter.CENTER, pady=(15,2))\n",
    "        btn_submit2=tkinter.Button(self.left_frame, text=\"Submit Image\", width=20, height=2, bg=\"azure3\", command=self.load_file)\n",
    "        btn_submit2.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        self.left_frame.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        \n",
    "        self.window.mainloop()\n",
    "    \n",
    "    #browsing picture files for databse creation\n",
    "    def load_file(self):\n",
    "        files =filedialog.askopenfilenames(initialdir = \"C:/Users/apurv\",title = \"Select file\",filetypes = ((\"jpg files\",\"*.jpg\"),(\"jpeg files\",\"*.jpeg\"),(\"png files\",\"*.png\")))\n",
    "        if files:\n",
    "            conn=self.create_or_open_dbpics('picture_db.sqlite')\n",
    "            for i in files:\n",
    "                print('yo')\n",
    "                self.insert_picture(conn,i)\n",
    "            conn.close()\n",
    "                 \n",
    "    #creating database for storing questions and their expected answers.\n",
    "    def create_or_open_dbtext_and_insert(self,db_file, ques, ans):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists QUESANS(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            QUES TEXT,\n",
    "            ANS TEXT);'''\n",
    "            conn.execute(sql) \n",
    "        else:\n",
    "            print ('Text Schema exists\\n')\n",
    "        sql = '''INSERT INTO QUESANS\n",
    "        (QUES,ANS)\n",
    "        VALUES(?,?);'''\n",
    "        conn.execute(sql,[ques,ans]) \n",
    "        print(\"yotext\")\n",
    "        conn.commit()\n",
    "        self.ques_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        conn.close()\n",
    "        #return conn\n",
    "    #creating database for storing pictures for text based description\n",
    "    def create_or_open_dbpics(self,db_file):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists PICTURES(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            FILENAME STRING,\n",
    "            PICTURE BLOB);'''\n",
    "            conn.execute(sql) \n",
    "        else:\n",
    "            print ('Pics Schema exists\\n')\n",
    "        return conn\n",
    "    #inserting pictures to the database    \n",
    "    def insert_picture(self,conn, picture_file):\n",
    "        with open(picture_file, 'rb') as input_file:\n",
    "            ablob = input_file.read()\n",
    "            #base=os.path.basename(picture_file)\n",
    "            #afile, ext = os.path.splitext(base)\n",
    "            sql = '''INSERT INTO PICTURES\n",
    "            (FILENAME,PICTURE)\n",
    "            VALUES(?,?);'''\n",
    "            conn.execute(sql,[picture_file,sqlite3.Binary(ablob)]) \n",
    "            conn.commit()\n",
    "\n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
