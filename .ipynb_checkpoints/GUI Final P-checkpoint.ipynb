{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'width' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7df00f9309b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;31m# Create a window and pass it to the Application object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Psychometric Analysis Tool\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-7df00f9309b6>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, window, window_title, video_source)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Create a canvas that can fit the above video source size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanvas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCENTER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpady\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# Display information at the bottom of the webcam feed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'width' is not defined"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import Toplevel\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "#import time\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "from tkinter import filedialog\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os.path\n",
    "from os import listdir, getcwd\n",
    "from IPython.core.display import Image\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import keyboard\n",
    "import threading\n",
    "\n",
    "class App:\n",
    "\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(True, True)\n",
    "        self.window.configure(background='honeydew4')\n",
    "        \n",
    "        #print(window.winfo_height())\n",
    "        #print(window.winfo_width())\n",
    "\n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=2, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.FLAT, bg=\"honeydew3\", command=self.displayx)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"honeydew3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "\n",
    "        self.left_frame = tkinter.Frame(window, bd=3, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        # Open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.window, self.video_source)\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tkinter.Canvas(self.left_frame, width=self.vid.width, height=self.vid.height)\n",
    "        self.canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)  \n",
    "        # Display information at the bottom of the webcam feed\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"honeydew2\", text=\"Emotion detection using webcam and microphone feed\\n\\nClick on Start button to start analysis.\\nClick on Stop button to stop analysis.\\nClick on Screenshot to start facial expression based emotion recognition.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,20))\n",
    "        #Buttons for starting and stopping video-audio analysis, and for taking a snapshot\n",
    "        btn_start=tkinter.Button(self.left_frame, text=\"Start\", width=30, bg=\"honeydew3\" , command=lambda:self.start_recording())\n",
    "        btn_start.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_stop=tkinter.Button(self.left_frame, text=\"Stop\", width=30, bg=\"honeydew3\" , command=lambda:self.stop_recording())\n",
    "        btn_stop.pack(anchor=tkinter.CENTER, pady=(5,5))\n",
    "        btn_snapshot=tkinter.Button(self.left_frame, text=\"Snapshot\", width=30, bg=\"honeydew3\", command=self.snapshot)\n",
    "        btn_snapshot.pack(anchor=tkinter.CENTER, pady=(5,15))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "\n",
    "        # Result to be displayed at the right of the webcam feed\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, bg=\"honeydew2\", relief=tkinter.RAISED)\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"honeydew2\", text=\"Emotion detection using webcam and microphone feed\\n\\n::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        self.results_box=tkinter.Text(self.result_frame, state='disabled', width=100, height=40, bg=\"honeydew3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "\n",
    "        self.flag = 1\n",
    "        \n",
    "        self.FORMAT=pyaudio.paInt16\n",
    "        self.CHANNELS=2\n",
    "        self.RATE=44100\n",
    "        self.CHUNK=1024\n",
    "        #RECORD_SECONDS = 10\n",
    "        self.FILE_NAME=\"RECORDING.wav\"\n",
    "        self.audio=pyaudio.PyAudio() #instantiate the pyaudio\n",
    "        #recording prerequisites\n",
    "        self.stream=self.audio.open(format=self.FORMAT,channels=self.CHANNELS, \n",
    "                          rate=self.RATE,\n",
    "                          input=True,\n",
    "                          frames_per_buffer=self.CHUNK)\n",
    "        #starting recording\n",
    "        self.frames2=[]\n",
    "        self.isrecording=False\n",
    "        \n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def displayx(self):\n",
    "        print(\"Tester output\")\n",
    "\n",
    "        \n",
    "    def start_recording(self):\n",
    "        self.isrecording = True\n",
    "        t = threading.Thread(target=self.record)\n",
    "        t.start()\n",
    "    def stop_recording(self):\n",
    "        self.isrecording = False\n",
    "        print(\"stop\")\n",
    "        #end of recording\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.audio.terminate()\n",
    "        #writing to file\n",
    "        wavfile=wave.open(self.FILE_NAME,'wb')\n",
    "        wavfile.setnchannels(self.CHANNELS)\n",
    "        wavfile.setsampwidth(self.audio.get_sample_size(self.FORMAT))\n",
    "        wavfile.setframerate(self.RATE)\n",
    "        wavfile.writeframes(b''.join(self.frames2))#append frames recorded to file\n",
    "        wavfile.close()\n",
    "        \n",
    "        # load json and create model\n",
    "        json_file = open('modelser.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"modelser.h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "        import numpy as np\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "        import scipy.io.wavfile\n",
    "        rate, data = scipy.io.wavfile.read(\"RECORDING.wav\")\n",
    "        #print (rate)\n",
    "        #print(len(data))\n",
    "        #print(data[0])\n",
    "        new=[]\n",
    "        for b in data:\n",
    "            b=max(b[0],b[1])\n",
    "            if b>0:\n",
    "                new.append(b)\n",
    "        print(len(new))\n",
    "        new=np.array(new)\n",
    "        l=len(new)\n",
    "        c=int(l/60000)\n",
    "        rec=[]\n",
    "        i=0\n",
    "        for i in range(0,c):\n",
    "            rec.append(new[60000*i:60000*(i+1)])\n",
    "        rec=np.array(rec)    \n",
    "        print(rec.shape)\n",
    "        rec=rec.reshape(c,40,1500)\n",
    "        for i in range(0,c):\n",
    "            find = rec[i]\n",
    "            find=find.reshape(1,75,800)\n",
    "            custom = loaded_model.predict(find)\n",
    "            percent_emot = custom[0]\n",
    "            output_emot = custom[0].tolist()\n",
    "            disp_output = \"\\n\\nSpeech Emotion \\nProbability assigned to each emotion class as percentage:\" + \"\\n\\nNeutral: \"+ str(output_emot[0]*100)+ \"\\n\\nCalm: \"+ str(output_emot[1]*100)+ \"\\n\\nHappy: \"+ str(output_emot[2]*100)+ \"\\n\\nSad: \"+ str(output_emot[3]*100) + \"\\n\\nAngry: \"+ str(output_emot[4]*100) + \"\\n\\nFearful: \"+ str(output_emot[5]*100) + \"\\n\\nDisgust: \" +str(output_emot[6]*100 )+\"\\n\\nSurprised: \" + str(output_emot[7]*100)  \n",
    "            print(disp_output)\n",
    "        \n",
    "        #self.results_box.config(state='normal')\n",
    "        #self.results_box.insert('end', disp_output)\n",
    "        #self.results_box.config(state='disable')\n",
    "        \n",
    "    def record(self):\n",
    "        self.FORMAT=pyaudio.paInt16\n",
    "        self.CHANNELS=2\n",
    "        self.RATE=44100\n",
    "        self.CHUNK=1024\n",
    "        #RECORD_SECONDS = 10\n",
    "        self.FILE_NAME=\"RECORDING.wav\"\n",
    "\n",
    "        self.audio=pyaudio.PyAudio() #instantiate the pyaudio\n",
    "        #recording prerequisites\n",
    "        self.stream=self.audio.open(format=self.FORMAT,channels=self.CHANNELS, \n",
    "                          rate=self.RATE,\n",
    "                          input=True,\n",
    "                          frames_per_buffer=self.CHUNK)\n",
    "        #starting recording\n",
    "        self.frames2=[]\n",
    "        while self.isrecording==1:\n",
    "            data=self.stream.read(self.CHUNK)\n",
    "            data_chunk=array('h',data)\n",
    "            vol=max(data_chunk)\n",
    "            if(vol>=500):\n",
    "                print(\"something said\")\n",
    "                self.frames2.append(data)\n",
    "            else:\n",
    "                print(\"nothing\")\n",
    "            print(\"\\n\")\n",
    "       \n",
    "        \n",
    "    def increase_brightness(self, img, value=30):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        lim = 255 - value\n",
    "        v[v > lim] = 255\n",
    "        v[v <= lim] += value\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "\n",
    "    def snapshot(self):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            # load json and create model\n",
    "            json_file = open('model.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "            # load weights into new model\n",
    "            loaded_model.load_weights(\"model.h5\")\n",
    "            # Face detection and FER\n",
    "            face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            snapshot = self.increase_brightness(frame, value=40)\n",
    "            gray = cv2.cvtColor(snapshot, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            print(faces)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = gray[y:y+h, x:x+w]\n",
    "                img = cv2.resize(roi,(48,48))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis = 0)\n",
    "                x /= 255\n",
    "                custom = loaded_model.predict(x)\n",
    "                percent_emot = custom[0]\n",
    "                #print(custom[0])\n",
    "                output_emot = custom[0].tolist();\n",
    "                #print(output_emot[0])\n",
    "                disp_output = \"Probability assigned to each emotion class as percentage:\", \"\\n\\nAngry: \", output_emot[0]*100, \"\\n\\nDisgust: \", output_emot[1]*100, \"\\n\\nFear: \", output_emot[2]*100, \"\\n\\nHappy: \", output_emot[3]*100, \"\\n\\nSad: \", output_emot[4]*100, \"\\n\\nSurprise: \", output_emot[5]*100, \"\\n\\nNeutral: \", output_emot[6]*100\n",
    "                self.results_box.config(state='normal')\n",
    "                self.results_box.insert(\"1.0\", disp_output)\n",
    "                self.results_box.config(state='disable')\n",
    "            #cv2.imwrite(\"frame-\" + time.strftime(\"%d-%m-%Y-%H-%M-%S\") + \".jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        \n",
    "        if ret:\n",
    "            self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "\n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "\n",
    "class MyVideoCapture:\n",
    "    def __init__(self, parent, video_source=0):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280);\n",
    "        #self.vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720);\n",
    "        # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    def detect(self, gray, frame):\n",
    "        # Now get the tuples that detect the faces using above cascade\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        # Now iterate over the faces and detect eyes\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 0), 2)\n",
    "        return frame\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            canvas = self.detect(gray, frame)\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "if __name__ == '__main__':\n",
    "    App(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import math\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "class Splitter(object):\n",
    "    def __init__(self):\n",
    "        self.nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    def split(self, text):\n",
    "        sentences = self.nltk_splitter.tokenize(text)\n",
    "        tokenized_sentences = [self.nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        return tokenized_sentences\n",
    "\n",
    "class POSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def pos_tag(self, sentences):\n",
    "        pos = [nltk.pos_tag(sentence) for sentence in sentences]\n",
    "        pos = [[(word, word, [postag]) for (word, postag) in sentence] for sentence in pos]\n",
    "        return pos\n",
    "\n",
    "class Screen2():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='SlateGray4')\n",
    "        \n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.FLAT, bg=\"SlateGray3\", command=self.displayx)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"SlateGray3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        self.global_picid=1\n",
    "        self.img=\"survival.jpg\"\n",
    "        self.eimg = PIL.ImageTk.PhotoImage(PIL.Image.open(self.img))\n",
    "        self.image_label = tkinter.Label(self.left_frame, image=self.eimg, width=800, height=560, bg=\"SlateGray2\")\n",
    "        self.image_label.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #canvas = tkinter.Canvas(self.left_frame, bd=0, width=500, height=400)\n",
    "        #canvas.create_image(10, 10, image=eimg, anchor=tkinter.CENTER)\n",
    "        #canvas.config(scrollregion=canvas.bbox(tkinter.ALL))\n",
    "        #canvas.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        #Display information below image\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"SlateGray2\", text=\"Picture description based test\\n\\nClick on Next button to go to next picture.\\nClick on Previous button to go to previous picture.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        #Buttons for navigating through pictures/images\n",
    "        btn_prev=tkinter.Button(self.left_frame, text=\"<< Previous\", width=20, height=3, bg=\"SlateGray3\", command=lambda:self.extract_picture(1))\n",
    "        btn_prev.pack(side=tkinter.LEFT, pady=(10,10))\n",
    "        btn_next=tkinter.Button(self.left_frame, text=\"Next >>\", width=20, height=3, bg=\"SlateGray3\", command=lambda:self.extract_picture(2))\n",
    "        btn_next.pack(side=tkinter.RIGHT, pady=(10,10))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "        \n",
    "        # Result to be displayed at the right of the image\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"SlateGray2\")\n",
    "        ans_lab=tkinter.Label(self.result_frame, bg=\"SlateGray2\", text=\"Picture description based test\")\n",
    "        ans_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.ans_box=tkinter.Text(self.result_frame, width=100, height=18, bg=\"SlateGray3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        btn_submit=tkinter.Button(self.result_frame, text=\"Submit\", width=20, bg=\"SlateGray3\", command=lambda:self.submit_text(self.ans_box.get(\"1.0\",\"e-1c\")))\n",
    "        btn_submit.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"SlateGray2\", text=\"::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.results_box=tkinter.Text(self.result_frame, state='disabled', width=100, height=19, bg=\"SlateGray3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "        \n",
    "        self.window.mainloop()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def extract_picture(self,index):\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = self.create_or_open_dbpics('picture_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        pic_id=self.global_picid\n",
    "        \n",
    "        \n",
    "        cur.execute(\"SELECT MAX(ID) FROM PICTURES\")\n",
    "        for row in cur:\n",
    "            print(row[0])\n",
    "            max_id=row[0]\n",
    "        print(max_id,pic_id)\n",
    "        if pic_id==1 and index==1:\n",
    "            pid=max_id\n",
    "            \n",
    "        elif pic_id==max_id and index==2:\n",
    "            pid=1\n",
    "            \n",
    "        elif index==1:\n",
    "            pid=pic_id-1\n",
    "            \n",
    "        else:\n",
    "            pid=pic_id+1\n",
    "            \n",
    "        self.global_picid=pid    \n",
    "        cur.execute(\"SELECT FILENAME,PICTURE FROM PICTURES WHERE ID = ?\",(pid,))\n",
    "        for row in cur:    \n",
    "            name=row[0]\n",
    "            \n",
    "        with open(name, 'rb') as input_file:\n",
    "            ablob = input_file.read()\n",
    "            #base=os.path.basename(pic)\n",
    "            #afile, ext = os.path.splitext(base)\n",
    "        \n",
    "        #filename = afile + ext\n",
    "        with open(name, 'wb') as output_file:\n",
    "            output_file.write(ablob)\n",
    "            \n",
    "        #self.eimg.destroy()    \n",
    "        #self.image_label.destroy()\n",
    "        #image = Image.open(filename)\n",
    "        self.img=name\n",
    "        #photo = ImageTk.PhotoImage(image)\n",
    "        self.eimg= PIL.ImageTk.PhotoImage(PIL.Image.open(name))\n",
    "        #label = Label(root,image=eimg)\n",
    "        #self.image_label=tkinter.Label(self.left_frame, image=self.eimg, width=150, height=90, bg=\"SlateGray2\")\n",
    "        #self.image_label.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10), expand=True)\n",
    "        self.image_label.configure(image=None)\n",
    "        self.image_label.configure(image=self.eimg)\n",
    "        #self.left_frame.update_idletasks()\n",
    "        print('changed')\n",
    "        #label.image = photo # keep a reference!\n",
    "        #label.pack()\n",
    "        return\n",
    "\n",
    "        \n",
    "    def create_or_open_dbpics(self,db_file):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists PICTURES(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            FILENAME STRING,\n",
    "            PICTURE BLOB);'''\n",
    "            conn.execute(sql)\n",
    "        else:\n",
    "            print ('Pics Schema exists\\n')\n",
    "        return conn\n",
    "\n",
    "    \n",
    "    def submit_text(self, ans):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        #print(ans)\n",
    "        # send this ans for sentiment analysis\n",
    "        createfeed=pd.read_csv('lterm_freq_tfidff.csv',index_col=0)\n",
    "        feature_values=[0,0,0]\n",
    "        str_result = self.text_cleaner(ans)\n",
    "        words= str_result.split()\n",
    "        for j in range(0, len(words)):\n",
    "            try:\n",
    "                feature_values = np.add(feature_values,[createfeed.loc[words[j]][0],createfeed.loc[words[j]][1],createfeed.loc[words[j]][2]])\n",
    "            except:\n",
    "                continue\n",
    "        self.results_box.config(state='normal')\n",
    "        try:\n",
    "            feature_values = feature_values.tolist()\n",
    "            feature_values = np.array(feature_values)\n",
    "            final_feature_values = []\n",
    "            final_feature_values.append(feature_values)\n",
    "            final_feature_values = np.array(final_feature_values)\n",
    "            # load json and create model\n",
    "            json_file = open('modelsenti.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "            # load weights into new model\n",
    "            loaded_model.load_weights(\"modelsenti.h5\")\n",
    "            # Predict sentiment class using model\n",
    "            custom = loaded_model.predict(final_feature_values)\n",
    "            output_emot = custom[0].tolist();\n",
    "            disp_output = \"Probability assigned to each sentiment class as percentage:\", \"\\n\\nNegative: \", output_emot[0]*100, \"\\n\\nNeutral: \", output_emot[1]*100, \"\\n\\nPositive: \", output_emot[2]*100\n",
    "            self.results_box.insert(\"1.0\", disp_output)\n",
    "            #print(custom[0])\n",
    "        except:\n",
    "            self.results_box.insert(\"1.0\", \"A longer description is required to get accurate sentiment estimation.\")\n",
    "        self.results_box.config(state='disabled')\n",
    "            \n",
    "    \n",
    "    def text_cleaner(self, text):\n",
    "        splitter = Splitter()\n",
    "        tok = WordPunctTokenizer()\n",
    "        postagger = POSTagger()\n",
    "        negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                    \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                    \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                    \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                    \"mustn't\":\"must not\"}\n",
    "\n",
    "        neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "        lower_case=\"\"\n",
    "        for i in range(0,len(text)):\n",
    "            if text[i].isalpha():\n",
    "                lower_case=lower_case+text[i].lower()\n",
    "            elif text[i].isdigit():\n",
    "                lower_case=lower_case\n",
    "            else:\n",
    "                lower_case=lower_case+text[i]\n",
    "        neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "        words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "        forpos= \" \".join(words).strip()\n",
    "        splitted_sentences = splitter.split(forpos)\n",
    "        pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "        altered_text=\"\"\n",
    "        for sentences in pos_tagged_sentences:\n",
    "            for word in sentences:\n",
    "                v=word[2]\n",
    "                for val in v:\n",
    "                    if (val==\"JJ\" or val==\"JJR\" or val==\"JJS\" or val==\"VB\" or val==\"VBD\" or val==\"VBG\"\n",
    "                        or val==\"VBN\" or val==\"VBP\" or val==\"VBZ\" or val==\"RB\" or val==\"RBR\" or val==\"RBS\" ):\n",
    "                        altered_text=altered_text+word[0]+\" \"\n",
    "        return altered_text\n",
    "\n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Screen3():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='LemonChiffon4')\n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.FLAT, bg=\"LemonChiffon3\", command=self.displayx)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.RAISED, bg=\"LemonChiffon3\", command=self.screen_four)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.global_quesid=1\n",
    "        #ques_to_display=\"Which city is known as the PITAL NAGRI\"\n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        ques_label = tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Question\")\n",
    "        ques_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ques_box=tkinter.Text(self.left_frame, width=100, height=14, bg=\"LemonChiffon3\")\n",
    "        self.ques_box.insert(\"1.0\", \"Click on Next to display question.\")\n",
    "        self.ques_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        ans_label = tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Answer\")\n",
    "        ans_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ans_box=tkinter.Text(self.left_frame, width=100, height=14, bg=\"LemonChiffon3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        label_header=tkinter.Label(self.left_frame, bg=\"LemonChiffon2\", text=\"Situational judgement based test\\n\\nClick on Next button to go to next question.\\nClick on Previous button to go to previous question.\")\n",
    "        label_header.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        #Buttons for displaying answer and navigating through questions\n",
    "        #btn_display=tkinter.Button(self.left_frame, text=\"Display answer\", width=20, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(self.ques_box.get(\"1.0\",\"end-1c\"),1))\n",
    "        #btn_display.pack(anchor=tkinter.CENTER, pady=(5,10))\n",
    "        btn_prev=tkinter.Button(self.left_frame, text=\"<< Previous\", width=20, height=2, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(1))\n",
    "        btn_prev.pack(side=tkinter.LEFT, pady=(10,10))\n",
    "        btn_next=tkinter.Button(self.left_frame, text=\"Next >>\", width=20, height=2, bg=\"LemonChiffon3\", command=lambda:self.extract_quesans(2))\n",
    "        btn_next.pack(side=tkinter.RIGHT, pady=(10,10))\n",
    "        self.left_frame.pack(side=tkinter.LEFT, anchor=tkinter.CENTER, padx=(20,10), pady=(10,10))\n",
    "        \n",
    "        # Result to be displayed at the right\n",
    "        self.result_frame = tkinter.Frame(window, bd=3, relief=tkinter.RAISED, bg=\"LemonChiffon2\")\n",
    "        ans_lab=tkinter.Label(self.result_frame, bg=\"LemonChiffon2\", text=\"Situational judgement based test\")\n",
    "        ans_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.answ_box=tkinter.Text(self.result_frame, width=100, height=18, bg=\"LemonChiffon3\")\n",
    "        self.answ_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        btn_submit=tkinter.Button(self.result_frame, text=\"Submit\", width=20, bg=\"LemonChiffon3\", command=lambda:self.show_exp_answer_submit_given_ans(self.answ_box.get('1.0','end-1c')))\n",
    "        btn_submit.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        results_lab=tkinter.Label(self.result_frame, bg=\"LemonChiffon2\", text=\"::Results::\")\n",
    "        results_lab.pack(anchor=tkinter.CENTER, pady=(10,5))\n",
    "        self.results_box=tkinter.Text(self.result_frame, state='disabled', width=100, height=19, bg=\"LemonChiffon3\")\n",
    "        self.results_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(5,10))\n",
    "        self.result_frame.pack(side=tkinter.RIGHT, anchor=tkinter.CENTER, padx=(10,20), pady=(10,10), expand=\"true\")\n",
    "        \n",
    "        self.window.mainloop()\n",
    "    \n",
    "        \n",
    "        \n",
    "    def extract_quesans(self,index):\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = sqlite3.connect('quesans_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        qid=self.global_quesid\n",
    "        '''cur.execute(\"SELECT ID FROM QUESANS WHERE ID=?\", (qid,))\n",
    "        for row in cur:   \n",
    "            print(row[0])\n",
    "            qid=row[0]\n",
    "        '''\n",
    "        cur.execute(\"SELECT MAX(ID) FROM QUESANS\")\n",
    "        for row in cur:\n",
    "            print(row[0])\n",
    "            max_id=row[0]\n",
    "        \n",
    "        if qid==1 and index==1:\n",
    "            aid=max_id\n",
    "            \n",
    "        elif qid==1 and index==2:\n",
    "            aid=qid+1\n",
    "            \n",
    "        elif qid==max_id and index==2:\n",
    "            aid=1\n",
    "            \n",
    "        elif qid==max_id and index==1:\n",
    "            aid=qid-1\n",
    "            \n",
    "        elif index==1:\n",
    "            aid=qid-1\n",
    "            \n",
    "        else:\n",
    "            aid=qid+1\n",
    "        self.global_quesid=aid    \n",
    "        cur.execute(\"SELECT ID,QUES FROM QUESANS WHERE ID = ?\",(aid,))\n",
    "        new_qid,new_ques = cur.fetchone()\n",
    "        for r in cur:\n",
    "            print(r[0])\n",
    "            print(r[1])\n",
    "        print(new_ques)\n",
    "        self.ques_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ques_box.insert(\"1.0\",new_ques)\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.answ_box.delete(\"1.0\", 'end-1c')\n",
    "    \n",
    "    \n",
    "    def show_exp_answer_submit_given_ans(self,given_ans):\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        self.results_box.delete(\"1.0\", 'end-1c')\n",
    "        conn = sqlite3.connect('quesans_db.sqlite')\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute(\"SELECT MAX(ID) FROM QUESANS\")\n",
    "        for row in cur:\n",
    "            max_id=row[0]\n",
    "        qid=self.global_quesid\n",
    "        cur.execute(\"SELECT ANS FROM QUESANS WHERE ID=?\", (qid,))\n",
    "        for row in cur:   \n",
    "            exp_ans=row[0]\n",
    "        \n",
    "        print(qid,exp_ans)\n",
    "        self.ans_box.insert(\"1.0\",exp_ans)\n",
    "        print(given_ans)\n",
    "        \n",
    "        # similarity check\n",
    "        responses = []\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        responses.append(stemmer.stem(exp_ans))\n",
    "        responses.append(stemmer.stem(given_ans))\n",
    "        disp_results = \"Similarity measures:\", \"\\n\\nThe cosine similarity of the expected and given answer is \", self.cosine_sim(responses), \"\\n\\nThe jaccard similarity of the expected and given answer is \", self.jaccard_sim(responses[0], responses[1])\n",
    "        self.results_box.config(state='normal')\n",
    "        try:\n",
    "            self.results_box.insert(\"1.0\", disp_results)\n",
    "            if self.cosine_sim(responses) > 0.3:\n",
    "                self.results_box.insert(\"end\", \"\\n\\nThe cosine similarity is greater than 0.2, which implies that the two responses have a good degree of similarity\")\n",
    "            if self.jaccard_sim(responses[0], responses[1]) > 0.2:\n",
    "                self.results_box.insert(\"end\", \"\\n\\nThe jaccard similarity is greater than 0.1, which implies that the two responses share a lot of similar words.\")\n",
    "        except:\n",
    "            self.results_box.insert(\"1.0\", \"Response cannot be compared\")\n",
    "        self.results_box.config(state='disabled')\n",
    "        #print(self.cosine_sim(responses))\n",
    "        #print(self.jaccard_sim(responses[0], responses[1]))\n",
    "        \n",
    "    def cosine_sim(self, strs):\n",
    "        vectorizer = CountVectorizer(strs)\n",
    "        vectorizer.fit(strs)\n",
    "        vectors = vectorizer.transform(strs).toarray()\n",
    "        return cosine_similarity(vectors)[0][1]\n",
    "    \n",
    "    def jaccard_sim(self, str1, str2):\n",
    "        a = set(str1.split())\n",
    "        b = set(str2.split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    \n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_four(self):\n",
    "        self.window.destroy()\n",
    "        Screen4(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os.path\n",
    "from os import listdir, getcwd\n",
    "from IPython.core.display import Image\n",
    "\n",
    "class Screen4():\n",
    "\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.wm_state('zoomed')\n",
    "        self.window.resizable(False, False)\n",
    "        self.window.configure(background='azure4')\n",
    "        \n",
    "        # Create a toolbar for choosing psychometric analysis method\n",
    "        self.toolbar_frame = tkinter.Frame(window, bd=1, relief=tkinter.RAISED, bg=\"azure2\")\n",
    "        eimg1 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"mind2.png\"))\n",
    "        toolButton1 = tkinter.Button(self.toolbar_frame, image=eimg1, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_one)\n",
    "        toolButton1.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg2 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"perspective2.png\"))\n",
    "        toolButton2 = tkinter.Button(self.toolbar_frame, image=eimg2, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_two)\n",
    "        toolButton2.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg3 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"qa2.png\"))\n",
    "        toolButton3 = tkinter.Button(self.toolbar_frame, image=eimg3, relief=tkinter.RAISED, bg=\"azure3\", command=self.screen_three)\n",
    "        toolButton3.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        eimg4 = PIL.ImageTk.PhotoImage(PIL.Image.open(\"user2.png\"))\n",
    "        toolButton4 = tkinter.Button(self.toolbar_frame, image=eimg4, relief=tkinter.FLAT, bg=\"azure3\", command=self.displayx)\n",
    "        toolButton4.pack(side=tkinter.LEFT, padx=2, pady=2)\n",
    "        self.toolbar_frame.pack(side=tkinter.TOP, padx=(10,10), pady=(10,10))\n",
    "        \n",
    "        self.left_frame = tkinter.Frame(window, bd=3, relief=tkinter.SUNKEN, bg=\"azure2\")\n",
    "        ques_label = tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Enter question to be submitted\")\n",
    "        ques_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ques_box=tkinter.Text(self.left_frame, width=100, height=15, bg=\"azure3\")\n",
    "        self.ques_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,10))\n",
    "        ans_label = tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Enter answer for the question\")\n",
    "        ans_label.pack(anchor=tkinter.CENTER, pady=(10,2), expand=True)\n",
    "        self.ans_box=tkinter.Text(self.left_frame, width=100, height=15, bg=\"azure3\")\n",
    "        self.ans_box.pack(anchor=tkinter.CENTER, padx=(10,10), pady=(10,2))\n",
    "        btn_submit1=tkinter.Button(self.left_frame, text=\"Submit Q/A\", width=20, height=2, bg=\"azure3\",\n",
    "                                   command=lambda:self.create_or_open_dbtext_and_insert(\"quesans_db.sqlite\", self.ques_box.get('1.0',\"end-1c\"), self.ans_box.get('1.0',\"end-1c\")))\n",
    "        btn_submit1.pack(anchor=tkinter.CENTER, pady=(10,15))\n",
    "        image_label=tkinter.Label(self.left_frame, bg=\"azure2\", text=\"Select image(s) to be submitted\")\n",
    "        image_label.pack(anchor=tkinter.CENTER, pady=(15,2))\n",
    "        btn_submit2=tkinter.Button(self.left_frame, text=\"Submit Image\", width=20, height=2, bg=\"azure3\", command=self.load_file)\n",
    "        btn_submit2.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        self.left_frame.pack(anchor=tkinter.CENTER, pady=(10,10))\n",
    "        \n",
    "        self.window.mainloop()\n",
    "    \n",
    "    #browsing picture files for databse creation\n",
    "    def load_file(self):\n",
    "        files =filedialog.askopenfilenames(initialdir = \"C:/Users/apurv\",title = \"Select file\",filetypes = ((\"jpg files\",\"*.jpg\"),(\"jpeg files\",\"*.jpeg\"),(\"png files\",\"*.png\")))\n",
    "        if files:\n",
    "            conn=self.create_or_open_dbpics('picture_db.sqlite')\n",
    "            for i in files:\n",
    "                print('yo')\n",
    "                self.insert_picture(conn,i)\n",
    "            conn.close()\n",
    "                 \n",
    "    #creating database for storing questions and their expected answers.\n",
    "    def create_or_open_dbtext_and_insert(self,db_file, ques, ans):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists QUESANS(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            QUES TEXT,\n",
    "            ANS TEXT);'''\n",
    "            conn.execute(sql) \n",
    "        else:\n",
    "            print ('Text Schema exists\\n')\n",
    "        sql = '''INSERT INTO QUESANS\n",
    "        (QUES,ANS)\n",
    "        VALUES(?,?);'''\n",
    "        conn.execute(sql,[ques,ans]) \n",
    "        print(\"yotext\")\n",
    "        conn.commit()\n",
    "        self.ques_box.delete(\"1.0\", 'end-1c')\n",
    "        self.ans_box.delete(\"1.0\", 'end-1c')\n",
    "        conn.close()\n",
    "        #return conn\n",
    "    #creating database for storing pictures for text based description\n",
    "    def create_or_open_dbpics(self,db_file):\n",
    "        db_is_new = not os.path.exists(db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        if db_is_new:\n",
    "            print ('Creating schema')\n",
    "            sql = '''create table if not exists PICTURES(\n",
    "            ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            FILENAME STRING,\n",
    "            PICTURE BLOB);'''\n",
    "            conn.execute(sql) \n",
    "        else:\n",
    "            print ('Pics Schema exists\\n')\n",
    "        return conn\n",
    "    #inserting pictures to the database    \n",
    "    def insert_picture(self,conn, picture_file):\n",
    "        with open(picture_file, 'rb') as input_file:\n",
    "            ablob = input_file.read()\n",
    "            #base=os.path.basename(picture_file)\n",
    "            #afile, ext = os.path.splitext(base)\n",
    "            sql = '''INSERT INTO PICTURES\n",
    "            (FILENAME,PICTURE)\n",
    "            VALUES(?,?);'''\n",
    "            conn.execute(sql,[picture_file,sqlite3.Binary(ablob)]) \n",
    "            conn.commit()\n",
    "\n",
    "    def displayx(self):\n",
    "        print('Tester output')\n",
    "    \n",
    "    def screen_one(self):\n",
    "        self.window.destroy()\n",
    "        App(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_two(self):\n",
    "        self.window.destroy()\n",
    "        Screen2(tkinter.Tk(), \"Psychometric Analysis Tool\")\n",
    "    \n",
    "    def screen_three(self):\n",
    "        self.window.destroy()\n",
    "        Screen3(tkinter.Tk(), \"Psychometric Analysis Tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "img = cv2.imread('sadd.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('sadd2.png', img)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x /= 255\n",
    "custom = loaded_model.predict(x)\n",
    "percent_emot = custom[0]\n",
    "#print(custom[0])\n",
    "output_emot = custom[0].tolist();\n",
    "#print(output_emot[0])\n",
    "disp_output = \"Probability assigned to each emotion class as percentage:\", \"\\n\\nAngry: \", output_emot[0]*100, \"\\n\\nDisgust: \", output_emot[1]*100, \"\\n\\nFear: \", output_emot[2]*100, \"\\n\\nHappy: \", output_emot[3]*100, \"\\n\\nSad: \", output_emot[4]*100, \"\\n\\nSurprise: \", output_emot[5]*100, \"\\n\\nNeutral: \", output_emot[6]*100\n",
    "print(disp_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
